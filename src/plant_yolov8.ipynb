{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv8 Plant Object Detection (TensorFlow Export)\n",
        "\n",
        "This notebook trains a YOLOv8 model to detect plant objects using a dataset fetched from an API endpoint. Training runs with Ultralytics (PyTorch backend) and the trained model is exported to TensorFlow SavedModel for TF-based inference.\n",
        "\n",
        "Workflow:\n",
        "- Install dependencies (Ultralytics, TensorFlow, etc.)\n",
        "- Configure API endpoint and local paths\n",
        "- Download and prepare dataset in YOLO format\n",
        "- Train YOLOv8 model\n",
        "- Validate/test performance\n",
        "- Run inference on a user-provided image\n",
        "- Export to TensorFlow SavedModel and run a basic TF inference demo\n",
        "\n",
        "Notes:\n",
        "- The API is expected to return a ZIP containing images and labels. If labels are not in YOLO format, the helper will attempt a simple split and use provided labels if available; otherwise you may need to adapt the preparation cell.\n",
        "- Set the configuration variables in the next cell to match your API and environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "pip install -q --upgrade pip\n",
        "pip install -q ultralytics==8.3.29 tensorflow==2.16.1 onnx==1.16.1 onnxruntime==1.18.1 tf2onnx==1.16.1 opencv-python matplotlib tqdm requests pyyaml supervision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, platform, os, shutil, zipfile, random, json, time\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "except Exception as e:\n",
        "    print(\"PyTorch not installed yet or no CUDA available.\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(f\"TensorFlow: {tf.__version__}\")\n",
        "    print(f\"TF GPU: {len(tf.config.list_physical_devices('GPU'))>0}\")\n",
        "except Exception as e:\n",
        "    print(\"TensorFlow not installed yet.\")\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure base dirs\n",
        "BASE_DIR = Path.cwd()\n",
        "DATA_DIR = BASE_DIR / 'data' / 'plant'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "YOLO_DIR = DATA_DIR / 'yolo'\n",
        "for d in [DATA_DIR, RAW_DIR, YOLO_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('Dirs ready:', DATA_DIR, RAW_DIR, YOLO_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "API_DATA_URL = os.environ.get('PLANT_API_ZIP_URL', 'https://your-api.example.com/plant-dataset.zip')\n",
        "API_HEADERS_JSON = os.environ.get('PLANT_API_HEADERS_JSON', '{}')  # e.g. '{\"Authorization\": \"Bearer <TOKEN>\"}'\n",
        "DATASET_NAME = 'plant'\n",
        "CLASS_NAMES = ['plant']  # Update if multiple classes\n",
        "VAL_SPLIT = 0.2\n",
        "RANDOM_SEED = 42\n",
        "MODEL_VARIANT = 'yolov8n.pt'  # choose from yolov8n/s/m/l/x depending on GPU\n",
        "EPOCHS = 50\n",
        "IMG_SIZE = 640\n",
        "BATCH = 16\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print('Using API:', API_DATA_URL)\n",
        "print('Headers:', API_HEADERS_JSON)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset ZIP from API endpoint\n",
        "import requests\n",
        "\n",
        "headers = {}\n",
        "try:\n",
        "    headers = json.loads(API_HEADERS_JSON)\n",
        "except Exception as e:\n",
        "    print('Invalid headers JSON, using empty headers')\n",
        "\n",
        "zip_path = RAW_DIR / 'dataset.zip'\n",
        "if not zip_path.exists():\n",
        "    print('Downloading dataset...')\n",
        "    with requests.get(API_DATA_URL, headers=headers, stream=True, timeout=120) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    print('Downloaded to', zip_path)\n",
        "else:\n",
        "    print('ZIP already exists at', zip_path)\n",
        "\n",
        "# Extract\n",
        "extract_dir = RAW_DIR / 'extracted'\n",
        "if extract_dir.exists():\n",
        "    shutil.rmtree(extract_dir)\n",
        "extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(extract_dir)\n",
        "\n",
        "print('Extracted to', extract_dir)\n",
        "\n",
        "# Inspect extracted structure\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    print(root, 'dirs:', len(dirs), 'files:', len(files))\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare YOLO dataset structure: data/yolo/{images,labels}/{train,val}\n",
        "\n",
        "image_exts = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "label_ext = '.txt'\n",
        "\n",
        "images_all = []\n",
        "labels_all = {}\n",
        "\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for f in files:\n",
        "        fp = Path(root) / f\n",
        "        ext = fp.suffix.lower()\n",
        "        if ext in image_exts:\n",
        "            images_all.append(fp)\n",
        "        elif ext == label_ext:\n",
        "            labels_all[fp.stem] = fp\n",
        "\n",
        "print(f'Total images found: {len(images_all)}')\n",
        "\n",
        "# Simple split\n",
        "random.shuffle(images_all)\n",
        "num_val = max(1, int(len(images_all) * VAL_SPLIT))\n",
        "val_images = set(p.stem for p in images_all[:num_val])\n",
        "\n",
        "for split in ['train', 'val']:\n",
        "    for sub in ['images', 'labels']:\n",
        "        (YOLO_DIR / sub / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "missing_labels = 0\n",
        "for img_path in images_all:\n",
        "    stem = img_path.stem\n",
        "    split = 'val' if stem in val_images else 'train'\n",
        "    dst_img = YOLO_DIR / 'images' / split / img_path.name\n",
        "    shutil.copy2(img_path, dst_img)\n",
        "\n",
        "    label_src = labels_all.get(stem)\n",
        "    dst_lbl = YOLO_DIR / 'labels' / split / f'{stem}.txt'\n",
        "    if label_src and label_src.exists():\n",
        "        shutil.copy2(label_src, dst_lbl)\n",
        "    else:\n",
        "        # If no label, create empty label file (treat as background)\n",
        "        missing_labels += 1\n",
        "        open(dst_lbl, 'w').close()\n",
        "\n",
        "print('Missing labels:', missing_labels)\n",
        "\n",
        "# Write data.yaml\n",
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    'path': str(YOLO_DIR),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'names': {i: name for i, name in enumerate(CLASS_NAMES)},\n",
        "}\n",
        "\n",
        "yaml_path = YOLO_DIR / 'data.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.safe_dump(data_yaml, f)\n",
        "\n",
        "print('Wrote', yaml_path)\n",
        "print(yaml.safe_dump(data_yaml))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train YOLOv8 model\n",
        "\n",
        "model = YOLO(MODEL_VARIANT)\n",
        "\n",
        "results = model.train(\n",
        "    data=str((YOLO_DIR / 'data.yaml').resolve()),\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMG_SIZE,\n",
        "    batch=BATCH,\n",
        "    project=str((BASE_DIR / 'runs').resolve()),\n",
        "    name='plant_yolov8',\n",
        ")\n",
        "\n",
        "print('Training complete. Best weights at:', model.best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate / test\n",
        "\n",
        "metrics = model.val()\n",
        "print(metrics)  # includes mAP50-95, precision, recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference on a user-provided image\n",
        "\n",
        "USER_IMAGE_PATH = os.environ.get('PLANT_TEST_IMAGE', '')  # or set a path here\n",
        "if not USER_IMAGE_PATH:\n",
        "    print('Set PLANT_TEST_IMAGE env var to an image path to run inference.')\n",
        "else:\n",
        "    infer_model = YOLO(model.best if hasattr(model, 'best') and model.best else model)\n",
        "    res = infer_model.predict(source=USER_IMAGE_PATH, imgsz=IMG_SIZE, conf=0.25)\n",
        "    for r in res:\n",
        "        im = r.plot()  # BGR image\n",
        "        save_path = BASE_DIR / 'runs' / 'detect' / 'plant_infer'\n",
        "        save_path.mkdir(parents=True, exist_ok=True)\n",
        "        out_file = save_path / f\"result_{Path(USER_IMAGE_PATH).name}\"\n",
        "        cv2.imwrite(str(out_file), im)\n",
        "        print('Saved result to', out_file)\n",
        "\n",
        "    # Show inline\n",
        "    bgr = cv2.imread(USER_IMAGE_PATH)\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(8,6)); plt.imshow(rgb); plt.axis('off'); plt.title('Input')\n",
        "    plt.show()\n",
        "\n",
        "    rgb_out = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(8,6)); plt.imshow(rgb_out); plt.axis('off'); plt.title('Detections')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to TensorFlow SavedModel and basic TF inference demo\n",
        "\n",
        "# Export - Ultralytics supports export to multiple formats; we'll use tf SavedModel\n",
        "export_dir = BASE_DIR / 'exports'\n",
        "export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "export_results = model.export(format='tf', imgsz=IMG_SIZE, keras=False)  # creates folder next to weights\n",
        "print('Exported to:', export_results)\n",
        "\n",
        "# Locate SavedModel directory\n",
        "saved_model_dir = None\n",
        "if isinstance(export_results, (str, Path)):\n",
        "    saved_model_dir = Path(export_results)\n",
        "else:\n",
        "    # If export returns a dict-like, attempt to find the tf path\n",
        "    try:\n",
        "        saved_model_dir = Path(export_results.get('tf'))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print('SavedModel at:', saved_model_dir)\n",
        "\n",
        "# Basic TF inference using onnxruntime or tf.saved_model (depending on export)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    imported = tf.saved_model.load(str(saved_model_dir))\n",
        "    infer = imported.signatures.get('serving_default')\n",
        "    print('Loaded TF SavedModel')\n",
        "\n",
        "    # Prepare image\n",
        "    if USER_IMAGE_PATH:\n",
        "        img = cv2.imread(USER_IMAGE_PATH)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))\n",
        "        x = img_resized.astype('float32') / 255.0\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "        out = infer(tf.constant(x))\n",
        "        print('TF inference outputs:', list(out.keys()))\n",
        "    else:\n",
        "        print('Skip TF demo: set PLANT_TEST_IMAGE to run.')\n",
        "except Exception as e:\n",
        "    print('TF export/inference demo failed:', e)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
